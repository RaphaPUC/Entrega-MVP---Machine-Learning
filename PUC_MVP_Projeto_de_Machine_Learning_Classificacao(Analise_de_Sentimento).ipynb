{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaphaPUC/Entrega-MVP---Machine-Learning/blob/main/PUC_MVP_Projeto_de_Machine_Learning_Classificacao(Analise_de_Sentimento).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVP PUC-RIO"
      ],
      "metadata": {
        "id": "P1EMmqAeQeZ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rG3YACE4-WFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descrição do Problema\n",
        "\n",
        "O problema é a dificuldade dos usuários em encontrar filmes e séries que correspondam aos seus gostos individuais nos serviços de streaming, devido à vasta quantidade de opções disponíveis.\n",
        "\n",
        "A hipótese é que os usuários tendem a preferir conteúdo que reflete sentimentos positivos em resenhas e avaliações anteriores.\n",
        "\n",
        "Os dados selecionados devem incluir resenhas de filmes com sentimentos claramente identificáveis e avaliações dos usuários.\n",
        "\n",
        " O dataset consiste em resenhas de filmes do IMDb, incluindo o texto da resenha, a avaliação associada (positiva ou negativa), e o ID do filme.\n",
        "\n",
        "\n",
        "# Preparação de Dados\n",
        "O dataset já está separado em conjuntos de treino e teste, conforme indicado pelo código data.load_data() que retorna (x_train, y_train), (x_test, y_test). Não há menção a um conjunto de validação separado, mas é possível criar um usando uma fração do conjunto de treino, como mostrado no método model.fit() onde validation_split=0.2 reserva 20% dos dados de treino para validação.\n",
        "Operações de transformação de dados incluirão a normalização do texto e vetorização das palavras.\n",
        "A validação cruzada é útil para avaliar modelos, mas pode ser demorada e não é sempre necessária.\n",
        "No caso de Análise de Sentimento, a validação cruzada pode não ser necessária por conta do conjunto de dados do IMDB ser grande, então temos muitos dados para treinar. E o modelo já usa uma parte dos dados de treino para validação durante o treinamento. Então a validação cruzada seria demorada devido ao tamanho do conjunto de dados.\n",
        "A seleção de atributos se concentrará em palavras-chave e sentimentos expressos nas resenhas.\n",
        "\n",
        "\n",
        "# Modelagem e Treinamento\n",
        "Foi escolhido o Keras, um modelo popular que transforma palavras em números e entende a relação entre elas.\n",
        " Foram ajustados alguns detalhes do modelo para garantir que ele aprenda da melhor maneira.\n",
        " O modelo foi treinado corretamente, sem problemas de underfitting, o que significa que ele aprendeu bem com os dados.\n",
        " É possível melhorar ainda mais o modelo ajustando alguns detalhes, como a taxa de aprendizado.\n",
        "\n",
        "\n",
        "# Avaliação de Resultados\n",
        " Métricas de Avaliação: Foi executada uma métrica chamada SparseCategoricalAccuracy para avaliar o modelo.\n",
        "\n",
        "O modelo foi treinado com a base de treino e testado com a base de teste, conforme indicado pelas etapas de ajuste (fit) e avaliação (evaluate).\n",
        "\n",
        " Foi implementado o modelo LSTM para análise de sentimento. Mas que é adequado para sequências de texto devido à sua capacidade de capturar dependências de longo prazo."
      ],
      "metadata": {
        "id": "49ce8zBLlPvn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ixzf4Rary5o"
      },
      "source": [
        "# Análise de Sentimento - base IMDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PfBKRHiry5o"
      },
      "source": [
        "Etapas:\n",
        "\n",
        "- Carregar dados\n",
        "- Definir modelo Keras\n",
        "- Compilar modelo Keras\n",
        "- Ajustar (fit) modelo Keras\n",
        "- Avaliar (evalute) modelo Keras\n",
        "- Faça previsões (predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q8Qkehgry5o"
      },
      "source": [
        "## Carregar dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EZ6fwWWwry5p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "#Para evitar que o console fique poluído com mensagens desnecessárias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LYhMEtQry5p"
      },
      "outputs": [],
      "source": [
        "#Importando bibliotecas\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1FBePivry5p"
      },
      "outputs": [],
      "source": [
        "data = keras.datasets.imdb\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = data.load_data()\n",
        "#Importando dataset IMB, onde x_train é a lista de críticas de filmes e y_train de rótulos de sentimento (1 = positivo, 0 = negativo). x_test e y_test são os dados de teste de mesma estrutura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaY32W56ry5p"
      },
      "outputs": [],
      "source": [
        "x_train.shape, y_train.shape\n",
        "#x_train é um array de listas, onde cada lista representa uma crítica de filme. y_train é um array de rótulos, onde cada rótulo é 0 (para uma crítica negativa) ou 1 (para uma crítica positiva)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX-eDCwiry5p"
      },
      "outputs": [],
      "source": [
        "x_test.shape, y_test.shape\n",
        "#x_test.shape retorna o número total de críticas de filmes no conjunto de teste. y_test.shape retornará o número total de rótulos no conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgNFJ8Fyry5p"
      },
      "outputs": [],
      "source": [
        "x_train[0]\n",
        "#É a primeira crítica de filme no conjunto de treinamento. Cada crítica é uma lista de índices de palavras. Cada índice corresponde a uma palavra específica no vocabulário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTTs0NVXry5p"
      },
      "outputs": [],
      "source": [
        "len(x_train[0])\n",
        "#Retorna o comprimento da primeira crítica de filme no conjunto de treinamento, ou seja, o número de palavras na primeira crítica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxwbOgQnry5q"
      },
      "outputs": [],
      "source": [
        "y_train[:5]\n",
        "#Retorna os primeiros 5 rótulos no conjunto de treinamento. No contexto do conjunto de dados IMDB, cada rótulo é 0 (para uma crítica negativa) ou 1 (para uma crítica positiva).\n",
        "#Portanto, y_train[:5] retornará os rótulos de sentimento das primeiras 5 críticas no conjunto de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8VlSoQZry5q"
      },
      "outputs": [],
      "source": [
        "np.unique(y_train, return_counts=True)\n",
        "#Retorna os valores únicos em y_train e conta quantas vezes cada um aparece.\n",
        "#A expressão vai contar quantas críticas negativas e positivas existem no conjunto de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YRujmAhry5q"
      },
      "outputs": [],
      "source": [
        "word_index = data.get_word_index()\n",
        "# word_index\n",
        "#Criando um dicionário de palavras para índices a partir do conjunto de dados IMDB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hb05Avtry5q"
      },
      "outputs": [],
      "source": [
        "len(word_index)\n",
        "#Retorna o número de entradas no dicionário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQIAMR1Try5q"
      },
      "outputs": [],
      "source": [
        "word_index[\"the\"]\n",
        "#Retorna o índice único que representa a palavra “the”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQpBKBdkry5q"
      },
      "outputs": [],
      "source": [
        "for chave, valor in word_index.items():\n",
        "    if valor == 1:\n",
        "        print(chave)\n",
        "        #Retorna o índice único que representa o valor “1”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTZnT6ckry5q"
      },
      "outputs": [],
      "source": [
        "for review in x_train[:5]:\n",
        "    print(len(review))\n",
        "    #Imprime o número de palavras nas primeiras 5 críticas no conjunto de treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conceito de Token**"
      ],
      "metadata": {
        "id": "66BGZZBi0KSl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAzmoZnMry5q"
      },
      "source": [
        "No processamento de linguagem natural, como na análise de dados de texto do IMDB, um “token” é basicamente uma palavra. “Tokenização” é o processo de dividir o texto em palavras individuais, que chamamos de “tokens”. Isso é importante porque ajuda a transformar o texto em uma forma que os modelos de aprendizado de máquina podem entender e usar. Por exemplo, uma frase é dividida em palavras individuais, e cada palavra é um “token”."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2wriUQ8ry5r"
      },
      "source": [
        "Considere a frase \"Aprendendo processamento de linguagem natural\". Na tokenização, esta frase seria dividida em tokens individuais. Cada palavra representa um token:\n",
        "\n",
        "- Token 1: \"Aprendendo\"\n",
        "- Token 2: \"processamento\"\n",
        "- Token 3: \"de\"\n",
        "- Token 4: \"linguagem\"\n",
        "- Token 5: \"natural\"\n",
        "\n",
        "Neste exemplo, a frase original é decomposta em palavras isoladas, cada uma considerada um token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVWaT5Pqry5r"
      },
      "source": [
        "Um exemplo onde um token não é necessariamente uma palavra pode ser encontrado na tokenização baseada em caracteres ou sílabas. Por exemplo, na frase \"Incrível\", a tokenização por sílabas resultaria nos tokens \"In\", \"crí\", \"vel\". Aqui, cada sílaba é tratada como um token distinto, ao invés de cada palavra inteira. Este tipo de tokenização pode ser útil em tarefas de processamento de linguagem natural que exigem uma análise mais detalhada do texto, como na compreensão de padrões fonéticos ou na análise de idiomas com estruturas de palavras complexas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBTchCF7ry5r"
      },
      "source": [
        "- PAD é o token usado para preenchimento. Nós preenchemos todas as sequências para o mesmo comprimento, que é o comprimento da sequência mais longa.\n",
        "- START é o token usado para marcar o início de uma sequência.\n",
        "- UNK é o token usado para marcar palavras desconhecidas (palavras que não estão no vocabulário).\n",
        "- UNUSED é o token usado para preencher as posições não utilizadas em uma sequência."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparando o dicionário para ser usado em NLP, onde cada palavra é mapeada para um valor único, e quatro tokens especiais são adicionados para ajudar no processamento das sequências."
      ],
      "metadata": {
        "id": "B0Uh36VozZVj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEZlrMdVry5r"
      },
      "outputs": [],
      "source": [
        "word_index = {chave: (valor + 3) for chave, valor in word_index.items()}\n",
        "#O código está atualizando o dicionário word_index ao adicionar 3 a cada valor (índice) no dicionário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsyJjWKyry5r"
      },
      "outputs": [],
      "source": [
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "#Adicionando quatro novas palavras ao word_index. Essas palavras são especiais e usadas para tarefas específicas ao lidar com texto:\n",
        "#\"<PAD>\": Usado para preencher o texto para que todas as críticas tenham o mesmo tamanho.\n",
        "#\"<START>\": Marca o início de uma crítica.\n",
        "#\"<UNK>\": Representa uma palavra desconhecida ou muito rara.\n",
        "#\"<UNUSED>\"\": Um espaço reservado para palavras que não são usadas."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chave, valor in word_index.items():\n",
        "    if valor == 1:\n",
        "        print(chave)\n",
        "        #Imprimindo a chave (palavra) cujo valor (índice) é 1."
      ],
      "metadata": {
        "id": "yLd5_Hd-GFqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZAumeQCry5r"
      },
      "outputs": [],
      "source": [
        "def decode_review(text, index):\n",
        "    reverse_index = {value: key for key, value in index.items()}\n",
        "    return \" \".join([reverse_index.get(value, \"<UNK>\") for value in text])\n",
        "    #A função decode_review transforma uma lista de números em uma frase.\n",
        "    #Ela faz isso usando o dicionário que mapeia números para palavras. Se um número não está no dicionário, ela usa a palavra \"<UNK>\".\n",
        "    #Então, ela junta todas as palavras com espaços para formar uma frase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNgsUB_iry5r"
      },
      "outputs": [],
      "source": [
        "decode_review(x_train[0], word_index)\n",
        "#Transforma essa lista de números de volta em uma frase legível, onde cada número é substituído pela palavra correspondente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdJJc7J3ry5r"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "\n",
        "def print_review(text, width=50):\n",
        "    wrapper = textwrap.TextWrapper(width=width)\n",
        "    print(wrapper.fill(text))\n",
        "    #Permite que o código use a funcionalidade de formatação de texto do Python.\n",
        "    #Isso formata o texto para que cada linha tenha no máximo a largura especificada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCfeOB2_ry5r"
      },
      "outputs": [],
      "source": [
        "print_review(decode_review(x_train[0], word_index))\n",
        "#Após converter os tokens na revisão de volta para palavras.\n",
        "#Imprime a revisão decodificada onde cada linha tenha 50 caracteres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdl7nCPTry5r"
      },
      "source": [
        "https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qVz-Hkiry5s"
      },
      "outputs": [],
      "source": [
        "print_review(decode_review(x_train[3], word_index))\n",
        "#decodifica a quarta revisão no conjunto de treinamento (x_train[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeZ0ThlFry5s"
      },
      "outputs": [],
      "source": [
        "x_train = keras.utils.pad_sequences(\n",
        "    x_train,\n",
        "    value=word_index[\"<PAD>\"],\n",
        "    padding=\"post\",\n",
        "    truncating=\"post\",\n",
        "    maxlen=256\n",
        ")\n",
        "\n",
        "x_test = keras.utils.pad_sequences(\n",
        "    x_test,\n",
        "    value=word_index[\"<PAD>\"],\n",
        "    padding=\"post\",\n",
        "    truncating=\"post\",\n",
        "    maxlen=256\n",
        ")\n",
        "#pad_sequences= Cada sequência é uma revisão de filme representada como uma lista de tokens.\n",
        "#value=word_index[\"<PAD>\"]: Isso define o valor que será usado para preencher as sequências que são mais curtas que o comprimento máximo. No caso, <PAD> é um token especial que representa o preenchimento.\n",
        "#truncating=\"post\": Isso significa que as sequências que são mais longas que o comprimento máximo serão truncadas no final.\n",
        "#maxlen=256:Define o comprimento máximo para as sequências. Qualquer sequência que seja mais longa que isso será truncada e qualquer sequência que seja mais curta que isso será preenchida."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "808wmiTory5s"
      },
      "outputs": [],
      "source": [
        "print_review(decode_review(x_train[0], word_index))\n",
        "#Imprimindo a revisão decodificada.\n",
        "#<START>:Token especial que indica o início de uma revisão.\n",
        "#<PAD>:Token especial usado para preencher todas as sequências para o mesmo comprimento.Preenchemos todas as sequências para terem o mesmo comprimento da sequência mais longa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WyMNDX_ry5s"
      },
      "outputs": [],
      "source": [
        "x_train[0]\n",
        "#Cada número na matriz corresponde a uma palavra específica. Por exemplo, o número 1 representa a palavra <START>.\n",
        "#A sequência de números representa a ordem das palavras na revisão. Por exemplo, a sequência [1, 14, 22, 16, 43] representa a sequência de palavras <START> this film was just.\n",
        "#O número 0 representa o token especial <PAD>, que é usado para preencher todas as sequências para terem o mesmo comprimento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-pykmxdry5s"
      },
      "outputs": [],
      "source": [
        "print_review(decode_review(x_train[3], word_index))\n",
        "#Imprimindo a quarta revisão (índice 3) no conjunto de treinamento, que foi decodificada de números para palavras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tx7ObW5Fry5s"
      },
      "outputs": [],
      "source": [
        "for review in x_train[:5]:\n",
        "    print(len(review))\n",
        "    #Este é um loop for que itera sobre as primeiras 5 revisões no conjunto de treinamento.\n",
        "    #Imprime o comprimento da revisão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7ZCCiVbry5s"
      },
      "outputs": [],
      "source": [
        "x_train.shape\n",
        "#Formato dos dados de treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi8Cezvury5s"
      },
      "source": [
        "## Definir modelo Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PIGsRSzry5s"
      },
      "source": [
        "\n",
        "### Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06eF_at2ry5t"
      },
      "source": [
        "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2EiVP90ry5t"
      },
      "source": [
        "O Embedding no Keras funciona como um tradutor que transforma números, cada um representando uma palavra, em vetores de números reais em um espaço multidimensional. Cada vetor representa uma palavra de maneira única, capturando nuances de seu significado e relação com outras palavras. Por exemplo, na representação vetorial, palavras com significados semelhantes, como \"feliz\" e \"alegre\", ficarão próximas no espaço vetorial. Esses vetores são aprendidos durante o treinamento do modelo, permitindo que a máquina compreenda e processe textos de maneira mais eficaz. Isso é fundamental em tarefas como análise de sentimentos ou tradução automática, onde a compreensão do contexto e das nuances das palavras é crucial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EICSzo-MbLek"
      },
      "source": [
        "\n",
        "### RNNS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNNs\n",
        "Uma Rede Neural Recorrente (RNN) é um tipo de rede neural projetada para processar sequências, como dados de séries temporais ou texto. RNNs são únicas porque mantêm uma memória interna de entradas anteriores, permitindo-lhes capturar informações sobre a história da sequência. No entanto, RNNs padrão frequentemente têm dificuldade em aprender dependências de longo alcance devido ao problema do gradiente desaparecendo.\n",
        "\n",
        "RNN-rolled.png\n",
        "\n",
        "LSTM, ou Memória de Longo e Curto Prazo, é um tipo especial de RNN que aborda essa questão. Ela inclui mecanismos chamados portões que regulam o fluxo de informações, tornando-a capaz de lembrar e utilizar informações ao longo de sequências muito mais longas. Isso torna as LSTMs mais eficazes para tarefas onde entender o contexto estendido é crucial."
      ],
      "metadata": {
        "id": "aJFXa6cCatIU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Khf7xt_1ry5t"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential()\n",
        "#Inicializa um novo modelo sequencial.\n",
        "model.add(keras.layers.InputLayer(input_shape=(256,)))\n",
        "#Adiciona uma camada de entrada. Cada entrada para o modelo é um vetor de 256 dimensões.\n",
        "model.add(keras.layers.Embedding(len(word_index), 64))\n",
        "#Adiciona uma camada de incorporação. A camada de incorporação transforma inteiros positivos (índices) em vetores densos de tamanho fixo.\n",
        "model.add(keras.layers.LSTM(64, dropout=0.5))\n",
        "#Adiciona uma camada LSTM (Long Short-Term Memory). 64 é o número de unidades na camada LSTM. dropout=0.5, é a fração das unidades a serem descartadas durante o treinamento.\n",
        "model.add(keras.layers.Dense(2, activation=\"sigmoid\"))\n",
        "#Adiciona uma camada densa (também conhecida como camada totalmente conectada). A camada densa tem 2 unidades e usa a função de ativação sigmoid.\n",
        "model.summary()\n",
        "#Imprime um resumo do modelo, incluindo o número total de parâmetros e a forma de saída de cada camada.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y092SqyQry5t"
      },
      "source": [
        "## Compilar modelo Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOsCsbk-ry5u"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.Adam(1E-4)\n",
        "#Define o otimizador que será usado para treinar o modelo.\n",
        "loss = keras.losses.SparseCategoricalCrossentropy()\n",
        "#Define a função de perda que o modelo tentará minimizar durante o treinamento.\n",
        "metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "#Define a métrica que será usada para avaliar o desempenho do modelo durante o treinamento.\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "#Compila o modelo com o otimizador, função de perda e métricas especificados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISX621bNry5u"
      },
      "source": [
        "## Fit modelo Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBVTFyiIry5u"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=20,\n",
        "    batch_size=512,\n",
        "    validation_split=0.2,\n",
        "    verbose=1,\n",
        ")\n",
        "#Treinando o modelo usando os dados de treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWvl-nkvry5u"
      },
      "source": [
        "## Evaluate modelo Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hHe2-9Yry5u"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test, y_test)\n",
        "#Avalia o desempenho do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ3ixXbQry5u"
      },
      "source": [
        "## Predict modelo Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTsQ8Vtkry5u"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
        "#Plota a perda do modelo nos dados de treinamento em cada época.\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "#Plota a perda do modelo nos dados de validação em cada época.\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O gráfico ilustra a convergência e a possível ocorrência de overfitting, onde a perda de validação começa a aumentar enquanto a perda continua diminuindo. Isso sugere que o modelo pode estar se ajustando demais aos dados de treinamento e perdendo a capacidade de generalizar para dados não vistos."
      ],
      "metadata": {
        "id": "i4RXEGsLcdAi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOfjGcj8ry5u"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"sparse_categorical_accuracy\"], label=\"accuracy\")\n",
        "#Plota a precisão do modelo nos dados de treinamento em cada época.\n",
        "plt.plot(history.history[\"val_sparse_categorical_accuracy\"], label=\"val_accuracy\")\n",
        "#Plota a precisão do modelo nos dados de validação em cada época.\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "É interessante porque visualiza a melhoria do desempenho ao longo do tempo, indicando como o modelo aprende e se ajusta aos dados durante o treinamento. Normalmente, espera-se que a precisão de validação acompanhe a precisão do treinamento, mas se a precisão de validação começar a diminuir enquanto a precisão do treinamento continuar aumentando, isso pode indicar overfitting."
      ],
      "metadata": {
        "id": "fxSu9q8oc2vX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxLJ6dokry5v"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    #Loop \"for\" que itera sobre as primeiras 10 revisões no conjunto de teste.\n",
        "    print(\"Label: \", y_test[i])\n",
        "    #Imprime o rótulo verdadeiro da i-ésima revisão no conjunto de teste. O rótulo é o sentimento associado à revisão (positivo ou negativo).\n",
        "    print(\"Prediction (sigmoid): \", model.predict(np.expand_dims(x_test[i], axis=0), verbose=0).flatten())\n",
        "    #Faz uma previsão para a i-ésima revisão no conjunto de teste.\n",
        "    print(\"Prediction: \", np.argmax(model.predict(np.expand_dims(x_test[i], axis=0), verbose=0)))\n",
        "    #Imprime a classe prevista pelo modelo para a i-ésima revisão.\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p6_J9r3ry5v"
      },
      "outputs": [],
      "source": [
        "print_review(decode_review(x_test[5], word_index), width=80)\n",
        "#Esta função está decodificando a sexta revisão (índice 5) no conjunto de teste. As revisões são codificadas como sequências de números, onde cada número representa uma palavra específica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Qanmp0mry5v"
      },
      "outputs": [],
      "source": [
        "review_good = \"The movie was great! The animation and the graphics were out of this world. I would recommend this movie.\"\n",
        "review_bad = \"The movie was terrible. The animation was poor and the graphics were awful. I would not recommend this movie.\"\n",
        "#Criadas duas variaveis de avaliações (boa e ruim)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbUqDhCKry5v"
      },
      "outputs": [],
      "source": [
        "print_review(review_good)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-Iy0qv0ry5v"
      },
      "outputs": [],
      "source": [
        "print_review(review_bad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp7HmkvK2RB6"
      },
      "outputs": [],
      "source": [
        "def encode_review(text, index):\n",
        "    import string\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
        "    #Remove toda a pontuação do texto e converte todas as letras para minúsculas.\n",
        "    return [index.get(word, 2) for word in text.split(\" \")]\n",
        "    #Divide o texto em palavras usando espaços como delimitadores e converte cada palavra em um número usando o índice fornecido. Se uma palavra não está no índice, ela é convertida para o número 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcESoHL8ry5v"
      },
      "outputs": [],
      "source": [
        "encode_review(review_good, word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV_IgxzTry5w"
      },
      "outputs": [],
      "source": [
        "decode_review(encode_review(review_good, word_index), word_index)\n",
        "#Primeiro codifica a revisão positiva (review_good) em uma sequência de números usando a função encode_review, e depois decodifica essa sequência de volta em texto usando a função decode_review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2Ss2U_qry5w"
      },
      "outputs": [],
      "source": [
        "review_good = keras.utils.pad_sequences(\n",
        "    #Esta função transforma uma lista de sequências (listas de números inteiros) em uma matriz 2D.\n",
        "    [encode_review(review_good, word_index)],\n",
        "    #Cada revisão é uma lista de números, onde cada número representa uma palavra específica.\n",
        "    value=word_index[\"<PAD>\"],\n",
        "    #valor usado para preencher as sequências. Usando o número que representa a palavra especial <PAD>.\n",
        "    padding=\"post\",\n",
        "    #Caso uma sequência for mais curta que o comprimento limite, os valores de preenchimento serão adicionados no final da sequência.\n",
        "    truncating=\"post\",\n",
        "    #Se uma sequência for mais longa que o comprimento limite, os valores extras no final da sequência serão removidos.\n",
        "    maxlen=256\n",
        "    #Comprimento das sequências, todas as sequências terão este comprimento após o preenchimento/truncamento.\n",
        ")\n",
        "\n",
        "review_bad = keras.utils.pad_sequences(\n",
        "    [encode_review(review_bad, word_index)],\n",
        "    value=word_index[\"<PAD>\"],\n",
        "    padding=\"post\",\n",
        "    truncating=\"post\",\n",
        "    maxlen=256\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHlnI2aEry5w"
      },
      "outputs": [],
      "source": [
        "review_good"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eXocYziry5w"
      },
      "outputs": [],
      "source": [
        "review_bad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wtNv5ipry5w"
      },
      "outputs": [],
      "source": [
        "model.predict(review_good)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaqhFs3try5w"
      },
      "outputs": [],
      "source": [
        "model.predict(review_bad)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}